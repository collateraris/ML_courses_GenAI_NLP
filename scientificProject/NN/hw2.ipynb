{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFTMJ2v-5YpN"
      },
      "source": [
        "# Homework 2. Training networks in PyTorch\n",
        "\n",
        "Это домашнее задание посвящено отработки навыков по написанию и обучению нейронных сетей. Ваше задание реализовать обучение нейронной сети и выполнить задания по анализу сети в конце ноутбука.\n",
        "\n",
        "И не забывайте отвечать на вопросы и делать выводы -- за это тоже ставятся баллы. Удачи!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3dj1mfT5Yp4"
      },
      "source": [
        "### Data loading in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UKLLAvNt5Yp5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.utils.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h626FYAm5Yp6"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2oqonVb5Yp7"
      },
      "source": [
        "You will works with a MNIST dataset. It contains grayscale images of handwritten digits of size 28 x 28. The number of training objects is 60000.\n",
        "\n",
        "\n",
        "In pytorch, there is a special module to download MNIST. But for us it is more convinient to load the data ourselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3vZ3StbV5Yp7"
      },
      "outputs": [],
      "source": [
        "from util import load_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bOxvlgne5Yp9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz...\n",
            "train-images-idx3-ubyte.gz downloaded successfully.\n",
            "Downloading train-labels-idx1-ubyte.gz...\n",
            "train-labels-idx1-ubyte.gz downloaded successfully.\n",
            "Downloading t10k-images-idx3-ubyte.gz...\n",
            "t10k-images-idx3-ubyte.gz downloaded successfully.\n",
            "Downloading t10k-labels-idx1-ubyte.gz...\n",
            "t10k-labels-idx1-ubyte.gz downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train, X_test, y_test = load_mnist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q6eiPbL5Yp-"
      },
      "source": [
        "The code below prepares short data (train and val) for seminar purposes (use this data to quickly learn model on CPU and to tune the hyperparameters). Also, we prepare the full data (train_full and test) to train a final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0IJS2adK5Yp_",
        "outputId": "be9d80dc-2484-4c7b-ffad-d82b84692f91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 1, 28, 28)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shuffle data\n",
        "np.random.seed(0)\n",
        "idxs = np.random.permutation(np.arange(X_train.shape[0]))\n",
        "X_train, y_train = X_train[idxs], y_train[idxs]\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYzxQ2Mf5Yp_"
      },
      "source": [
        "Pytorch offers convinient class DataLoader for mini batch generation. You should pass instance of Tensor Dataset to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oOmqt8aE5Yp_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\twoli\\AppData\\Local\\Temp\\ipykernel_2904\\2761436466.py:3: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
            "  torch.from_numpy(y).long())\n"
          ]
        }
      ],
      "source": [
        "def get_loader(X, y, batch_size=64):\n",
        "    train = torch.utils.data.TensorDataset(torch.from_numpy(X).float(),\n",
        "                                       torch.from_numpy(y).long())\n",
        "    train_loader = torch.utils.data.DataLoader(train,\n",
        "                                               batch_size=batch_size)\n",
        "    return train_loader\n",
        "\n",
        "# for final model:\n",
        "train_loader_full = get_loader(X_train, y_train)\n",
        "test_loader = get_loader(X_test, y_test)\n",
        "# for validation purposes:\n",
        "train_loader = get_loader(X_train[:15000], y_train[:15000])\n",
        "val_loader = get_loader(X_train[15000:30000], y_train[15000:30000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bOfwqdwJ5YqA",
        "outputId": "f41c6b2c-c1fe-48b6-8382-e5980d16d843"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([15000, 1, 28, 28])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check number of objects\n",
        "val_loader.dataset.tensors[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRoL5vqr5YqB"
      },
      "source": [
        "### Building LeNet-5\n",
        "\n",
        "Convolutional layer (from Anton Osokin's presentation):\n",
        "![slide](https://github.com/nadiinchi/dl_labs/raw/master/convolution.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WokmLD85YqB"
      },
      "source": [
        "You need to implement Lenet-5:\n",
        "\n",
        "![Архитектура LeNet-5](https://www.researchgate.net/profile/Vladimir_Golovko3/publication/313808170/figure/fig3/AS:552880910618630@1508828489678/Architecture-of-LeNet-5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc-cF7o35YqD"
      },
      "source": [
        "Construct a network according to the image and code examples given above. Use ReLU nonlinearity (after all linear and convolutional layers). The network must support multiplying the number of convolutions in each convolutional layer by k.\n",
        "\n",
        "Please note that on the scheme the size of the image is 32 x 32 but in our code the size is 28 x 28.\n",
        "\n",
        "Do not apply softmax at the end of the forward pass!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWfeNQ9gPhXo"
      },
      "source": [
        "### <font color='red'>[TODO] Написание архитектуры Le-Net-5 </font>\n",
        "\n",
        "В этой части вам нужно реализовать архитектуру Le-Net-5, но учтите, что на вход изображения приходит 28x28.\n",
        "\n",
        "Для того, написать архитектуру используйте [nn.Conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), [nn.AvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html), [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html). Ориентируйтесь на картинку сверху в реализации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "k9AXOaVh5YqE"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Первый сверточный блок\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)  # 28x28 -> 28x28\n",
        "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)      # 28x28 -> 14x14\n",
        "        \n",
        "        # Второй сверточный блок\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)           # 14x14 -> 10x10\n",
        "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)     # 10x10 -> 5x5\n",
        "        \n",
        "        # Полносвязные слои\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### your code here: transform x using layers\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # Не используем softmax - это сделает CrossEntropyLoss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4BYDgVO5YqE"
      },
      "source": [
        "Let's count the number of the parameters in the network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "DMqTaKi_5YqF"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "JobCjm_Z5YqG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "61706"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(param.data.numpy().size for param \\\n",
        "               in model.parameters() if param.requires_grad)\n",
        "\n",
        "count_parameters(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p50aWdYI5YqG"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO04799z5YqH"
      },
      "source": [
        "Let's define the loss function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "xeBFcssY5YqH"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss() # loss includes softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "500YiRwa5YqI"
      },
      "source": [
        "Also, define a device where to store the data and the model (cpu or gpu):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "3HQo_6Kb5YqJ"
      },
      "outputs": [],
      "source": [
        "#device = torch.device('cpu')\n",
        "device = torch.device('cuda') # Uncomment this to run on GPU\n",
        "cnn = cnn.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK9sl8w_5YqK"
      },
      "source": [
        "During training, we will control the quality on the training and validation set. This produces duplicates of the code. That's why we will define a function evaluate_loss_acc to evaluate our model on different data sets. In the same manner, we define function train_epoch to perform one training epoch on traiing data. Please note that we will compute the training loss _after_ each epoch (not averaging it during epoch).\n",
        "\n",
        "In the propotypes, train and eval modes are noted. In our case, we don't need them (because we don't use neither dropout nor batch normalization). However, we will switch the regime so you can use this code in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-9aShtYQWkt"
      },
      "source": [
        "### <font color='red'>[TODO] Реализуйте функции обучение модели </font>\n",
        "\n",
        "В части вам нужно написать циклы обучения моделей, вы можете ориентировать на ноутбук семинара при их выполнении"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "5dQn4HuD5YqL"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, optimizer, train_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    for each batch\n",
        "    performs forward and backward pass and parameters update\n",
        "\n",
        "    Input:\n",
        "    model: instance of model (example defined above)\n",
        "    optimizer: instance of optimizer (defined above)\n",
        "    train_loader: instance of DataLoader\n",
        "\n",
        "    Returns:\n",
        "    nothing\n",
        "\n",
        "    Do not forget to set net to train mode!\n",
        "    \"\"\"\n",
        "    ### your code here\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate_loss_acc(loader, model, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluates loss and accuracy on the whole dataset\n",
        "\n",
        "    Input:\n",
        "    loader:  instance of DataLoader\n",
        "    model: instance of model (examle defined above)\n",
        "\n",
        "    Returns:\n",
        "    (loss, accuracy)\n",
        "\n",
        "    Do not forget to set net to eval mode!\n",
        "    \"\"\"\n",
        "    ### your code here\n",
        "    model.eval()  # Переводим модель в режим оценки\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():  # Отключаем вычисление градиентов\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            total_loss += loss.item() * data.size(0)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total += data.size(0)\n",
        "    \n",
        "    accuracy = correct / total\n",
        "    average_loss = total_loss / total\n",
        "    \n",
        "    return average_loss, accuracy\n",
        "\n",
        "\n",
        "def train(model, opt, train_loader, test_loader, criterion, n_epochs, \\\n",
        "          device, verbose=True):\n",
        "    \"\"\"\n",
        "    Performs training of the model and prints progress\n",
        "\n",
        "    Input:\n",
        "    model: instance of model (example defined above)\n",
        "    opt: instance of optimizer\n",
        "    train_loader: instance of DataLoader\n",
        "    test_loader: instance of DataLoader (for evaluation)\n",
        "    n_epochs: int\n",
        "\n",
        "    Returns:\n",
        "    4 lists: train_log, train_acc_log, val_log, val_acc_log\n",
        "    with corresponding metrics per epoch\n",
        "    \"\"\"\n",
        "    train_log, train_acc_log = [], []\n",
        "    val_log, val_acc_log = [], []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_epoch(model, opt, train_loader, criterion, device)\n",
        "        train_loss, train_acc = evaluate_loss_acc(train_loader,\n",
        "                                                  model, criterion,\n",
        "                                                  device)\n",
        "        val_loss, val_acc = evaluate_loss_acc(test_loader, model,\n",
        "                                              criterion, device)\n",
        "\n",
        "        train_log.append(train_loss)\n",
        "        train_acc_log.append(train_acc)\n",
        "\n",
        "        val_log.append(val_loss)\n",
        "        val_acc_log.append(val_acc)\n",
        "\n",
        "        if verbose:\n",
        "             print (('Epoch [%d/%d], Loss (train/test): %.4f/%.4f,'+\\\n",
        "               ' Acc (train/test): %.4f/%.4f' )\n",
        "                   %(epoch+1, n_epochs, \\\n",
        "                     train_loss, val_loss, train_acc, val_acc))\n",
        "\n",
        "    return train_log, train_acc_log, val_log, val_acc_log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIl21h4g5YqM"
      },
      "source": [
        "### <font color='red'>[TODO] Обучение модели </font>\n",
        "\n",
        "Train the neural network, using defined functions. Use Adam as an optimizer, learning_rate=0.001, number of epochs = 20. For hold out, use val_loader, not test_loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g9Z-1m-45YqN"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not NoneType",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[0;32m      5\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m----> 6\u001b[0m train_log, train_acc_log, val_log, val_acc_log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[13], line 89\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, opt, train_loader, test_loader, criterion, n_epochs, device, verbose)\u001b[0m\n\u001b[0;32m     86\u001b[0m val_log, val_acc_log \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m---> 89\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m evaluate_loss_acc(train_loader,\n\u001b[0;32m     91\u001b[0m                                               model, criterion,\n\u001b[0;32m     92\u001b[0m                                               device)\n\u001b[0;32m     93\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate_loss_acc(test_loader, model,\n\u001b[0;32m     94\u001b[0m                                           criterion, device)\n",
            "Cell \u001b[1;32mIn[13], line 25\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, optimizer, train_loader, criterion, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m---> 25\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not NoneType"
          ]
        }
      ],
      "source": [
        "### your code here\n",
        "# Определение критерия кросс-энтропии\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
        "\n",
        "# Обучение модели\n",
        "n_epochs = 20\n",
        "train_log, train_acc_log, val_log, val_acc_log = train(\n",
        "    cnn, optimizer, train_loader, val_loader, criterion, n_epochs, device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjpBaZ7fSiP7"
      },
      "source": [
        "### <font color='red'>[TODO] Проведите эксперименты с моделью </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE5cJCEc5Yqq"
      },
      "source": [
        "\n",
        "### Choosing  learning_rate and batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_plUpWK5Yqq"
      },
      "source": [
        "Plot accuracy on the training and testing set v. s. training epoch for different learning parameters: learning rate$ \\in \\{0.0001, 0.001, 0.01\\}$, batch size $\\in \\{64, 256\\}$.\n",
        "\n",
        "The best option is to plot training curves on the left graph and validation curves on the right graph with the shared y axis (use plt.ylim).\n",
        "\n",
        "How do learning rate and batch size affect the final quality of the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lc5mgJmZ5Yqr"
      },
      "outputs": [],
      "source": [
        "### your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEG3Nu9w5Yqs"
      },
      "source": [
        "### Changing the architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqMV5M1j5Yqs"
      },
      "source": [
        "Try to modify our architecture: increase the number of filters and to reduce the number of fully-connected layers.\n",
        "\n",
        "Insert numbers in the brackets:\n",
        "* LeNet-5 classic (6 and 16 convolutions):  training acc: ( )  validation acc: ( )\n",
        "* Number of convolutions x 4 (24 и 64 convolutions):  training acc: ( )  validation acc: ( )\n",
        "* Removing fully connected layer: the previous network with 1 FC layer: training acc: ( )  validation acc: ( )\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eqpd48i25Yqt"
      },
      "outputs": [],
      "source": [
        "### your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoX-g-5n5Yqu"
      },
      "source": [
        "Choose the learning rate, batch size and the architecture based on your experiments. Train a network on the full dataset and print accuracy on the full test set."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
